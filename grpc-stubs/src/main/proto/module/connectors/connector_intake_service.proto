syntax = "proto3";

package io.pipeline.connector.intake;

import "google/protobuf/timestamp.proto";
import "core/pipeline_core_types.proto";

option java_package = "io.pipeline.connector.intake";
option java_multiple_files = true;

// ============================================
// CONNECTOR-INTAKE-SERVICE
// Handles authentication, account lookup, metadata enrichment
// Agnostic to connector type (filesystem, database, API, etc.)
// ============================================

service ConnectorIntakeService {
  // Main streaming endpoint - connectors stream documents here (client-side streaming)
  // Client sends: SessionStart -> Document chunks -> completes stream
  // Server returns: Single response when all chunks processed
  rpc StreamDocuments(stream DocumentIntakeRequest) returns (DocumentIntakeResponse);

  // Register a new crawl session
  rpc StartCrawlSession(StartCrawlSessionRequest) returns (StartCrawlSessionResponse);

  // End a crawl session (for cleanup, orphan detection)
  rpc EndCrawlSession(EndCrawlSessionRequest) returns (EndCrawlSessionResponse);

  // Heartbeat to keep session alive
  rpc Heartbeat(HeartbeatRequest) returns (HeartbeatResponse);
}

// ============================================
// ADMIN SERVICE
// Separate service for connector administration
// ============================================

service ConnectorAdminService {
  // Register a new connector
  rpc RegisterConnector(RegisterConnectorRequest) returns (RegisterConnectorResponse);

  // Update connector configuration
  rpc UpdateConnector(UpdateConnectorRequest) returns (UpdateConnectorResponse);

  // Get connector details
  rpc GetConnector(GetConnectorRequest) returns (ConnectorRegistration);

  // Validate API key for a connector
  rpc ValidateApiKey(ValidateApiKeyRequest) returns (ValidateApiKeyResponse);

  // List all connectors for an account
  rpc ListConnectors(ListConnectorsRequest) returns (ListConnectorsResponse);

  // Enable/disable a connector
  rpc SetConnectorStatus(SetConnectorStatusRequest) returns (SetConnectorStatusResponse);

  // Delete a connector (soft delete)
  rpc DeleteConnector(DeleteConnectorRequest) returns (DeleteConnectorResponse);

  // Generate new API key for a connector
  rpc RotateApiKey(RotateApiKeyRequest) returns (RotateApiKeyResponse);

  // Get crawl history for a connector
  rpc GetCrawlHistory(GetCrawlHistoryRequest) returns (GetCrawlHistoryResponse);
}

// ============================================
// DOCUMENT STREAMING (Main Flow)
// ============================================

message DocumentIntakeRequest {
  // Session info (set once at stream start)
  oneof session_info {
    SessionStart session_start = 1;
    DocumentData document = 2;
  }
}

message SessionStart {
  string connector_id = 1;        // Pre-registered connector ID
  string api_key = 2;             // Authentication token
  string crawl_id = 3;            // Unique crawl/job ID
  CrawlMetadata crawl_metadata = 4;
}

message CrawlMetadata {
  string connector_type = 1;      // "filesystem", "confluence", "database", etc.
  string connector_version = 2;
  google.protobuf.Timestamp crawl_started = 3;
  string source_system = 4;       // Which system we're crawling
  map<string, string> parameters = 5; // Crawl parameters
}

message DocumentData {
  // Source identification
  string source_id = 1;           // ID in source system (file path, confluence page ID, etc.)
  string source_parent_id = 2;    // Parent in source system (folder, space, etc.)

  // Document metadata
  string filename = 3;
  string path = 4;                // Relative path/hierarchy
  string mime_type = 5;
  int64 size_bytes = 6;

  // Source system timestamps
  google.protobuf.Timestamp source_created = 7;
  google.protobuf.Timestamp source_modified = 8;
  google.protobuf.Timestamp source_accessed = 9;

  // Source system metadata
  string source_author = 10;
  string source_version = 11;
  repeated string source_tags = 12;
  map<string, string> source_metadata = 13;

  // Content
  oneof content {
    bytes raw_data = 14;         // For small files (< 5MB)
    StreamingChunk chunk = 15;   // For large files
  }

  // Optional client-provided document ID for deduplication
  string client_document_id = 16;

  // Checksum for validation
  string checksum = 17;           // SHA-256 or similar
  string checksum_type = 18;      // "SHA256", "MD5", etc.
}

message StreamingChunk {
  string document_ref = 1;        // Reference to correlate chunks
  int32 chunk_number = 2;
  bool is_last = 4;
  
  oneof chunk_type {
    io.pipeline.data.v1.Blob header = 3;        // First chunk: Blob with storage_ref
    bytes raw_data = 5;                         // Middle chunks: Raw file content
    BlobMetadata footer = 6;                    // Last chunk: Final metadata
  }
}

message BlobMetadata {
  int64 final_size = 1;           // Actual final size
  string checksum = 2;            // SHA256 of complete file
  io.pipeline.data.v1.ChecksumType checksum_type = 3;
  string s3_key = 4;              // Final S3 object key
  string s3_etag = 5;             // S3 ETag for verification
  google.protobuf.Timestamp completed_at = 6;
  map<string, string> final_metadata = 7;
}

message DocumentIntakeResponse {
  oneof response {
    SessionStartResponse session_response = 1;
    DocumentResponse document_response = 2;
    BatchDocumentResponse batch_response = 3;  // For client-streaming: summary of all documents
  }
}

// Response when client finishes streaming all documents
message BatchDocumentResponse {
  string session_id = 1;
  int32 total_documents = 2;
  int32 successful = 3;
  int32 failed = 4;
  repeated DocumentResponse results = 5;  // Individual results for each document
  string message = 6;
}

message SessionStartResponse {
  bool authenticated = 1;
  string session_id = 2;
  string message = 3;

  // Server returns enriched config
  ConnectorConfig config = 4;
}

message ConnectorConfig {
  string account_id = 1;          // Account this connector belongs to
  string s3_bucket = 2;           // Where documents will be stored
  string s3_base_path = 3;        // Base path in S3
  int64 max_file_size = 4;        // Max file size allowed
  int64 rate_limit_per_minute = 5;
  map<string, string> default_metadata = 6; // Metadata to add to all docs
}

message DocumentResponse {
  string source_id = 1;           // Echo back for correlation
  string document_id = 2;          // Assigned document ID
  string s3_key = 3;              // Where it was stored
  bool success = 4;
  string error_message = 5;
  bool was_update = 6;            // True if document already existed
  string previous_version = 7;    // Previous version if updated
}

// ============================================
// CRAWL SESSION MANAGEMENT
// ============================================

message StartCrawlSessionRequest {
  string connector_id = 1;
  string api_key = 2;
  string crawl_id = 3;            // Client-provided crawl ID
  CrawlMetadata metadata = 4;

  // For orphan detection
  bool track_documents = 5;       // Track all docs in this crawl
  bool delete_orphans = 6;        // Delete docs not seen in this crawl
}

message StartCrawlSessionResponse {
  bool success = 1;
  string session_id = 2;
  string crawl_id = 3;
  string message = 4;
}

message EndCrawlSessionRequest {
  string session_id = 1;
  string crawl_id = 2;
  CrawlSummary summary = 3;
}

message CrawlSummary {
  int32 documents_found = 1;
  int32 documents_processed = 2;
  int32 documents_failed = 3;
  int32 documents_skipped = 4;
  int64 bytes_processed = 5;
  google.protobuf.Timestamp started = 6;
  google.protobuf.Timestamp completed = 7;
  map<string, string> statistics = 8;
}

message EndCrawlSessionResponse {
  bool success = 1;
  int32 orphans_found = 2;        // Docs from previous crawl not seen
  int32 orphans_deleted = 3;      // If delete_orphans was true
  string message = 4;
}

// ============================================
// HEARTBEAT
// ============================================

message HeartbeatRequest {
  string session_id = 1;
  string crawl_id = 2;
  int32 documents_queued = 3;
  int32 documents_processing = 4;
  map<string, string> metrics = 5;
}

message HeartbeatResponse {
  bool session_valid = 1;
  ControlCommand command = 2;     // Server can control the crawl
  map<string, string> config_updates = 3;
}

enum ControlCommand {
  COMMAND_CONTINUE = 0;
  COMMAND_PAUSE = 1;
  COMMAND_STOP = 2;
  COMMAND_THROTTLE = 3;          // Slow down
  COMMAND_SPEED_UP = 4;          // Go faster
}

// ============================================
// CONNECTOR REGISTRATION (Admin API)
// How connectors get registered in the system
// ============================================

message ConnectorRegistration {
  string connector_id = 1;        // Unique ID
  string connector_name = 2;      // Human-readable name
  string connector_type = 3;      // "filesystem", "confluence", etc.
  string account_id = 4;          // Which account owns this

  // Authentication
  string api_key = 5;             // Generated API key

  // S3 Configuration
  string s3_bucket = 6;
  string s3_base_path = 7;        // e.g., "connectors/filesystem-prod/"

  // Default metadata for all documents
  map<string, string> default_metadata = 8;

  // Limits and configuration
  int64 max_file_size = 9;
  int64 rate_limit_per_minute = 10;
  bool active = 11;

  google.protobuf.Timestamp created = 12;
  google.protobuf.Timestamp updated = 13;
}

// ============================================
// ADMIN API MESSAGES
// ============================================

message RegisterConnectorRequest {
  string connector_name = 1;      // Human-readable name
  string connector_type = 2;      // "filesystem", "confluence", etc.
  string account_id = 3;          // Which account owns this

  // S3 Configuration
  string s3_bucket = 4;
  string s3_base_path = 5;        // e.g., "connectors/filesystem-prod/"

  // Default metadata for all documents
  map<string, string> default_metadata = 6;

  // Limits and configuration
  int64 max_file_size = 7;
  int64 rate_limit_per_minute = 8;
}

message RegisterConnectorResponse {
  bool success = 1;
  string connector_id = 2;        // Generated unique ID
  string api_key = 3;             // Generated API key
  string message = 4;
}

message UpdateConnectorRequest {
  string connector_id = 1;

  // Optional fields - only update if provided
  string connector_name = 2;
  string s3_bucket = 3;
  string s3_base_path = 4;
  map<string, string> default_metadata = 5;
  int64 max_file_size = 6;
  int64 rate_limit_per_minute = 7;
}

message UpdateConnectorResponse {
  bool success = 1;
  string message = 2;
  ConnectorRegistration connector = 3;
}

message GetConnectorRequest {
  string connector_id = 1;
}

message ValidateApiKeyRequest {
  string connector_id = 1;
  string api_key = 2;
}

message ValidateApiKeyResponse {
  bool valid = 1;
  string message = 2;
  ConnectorRegistration connector = 3;  // If valid, return full config
}

message ListConnectorsRequest {
  string account_id = 1;          // Optional: filter by account
  int32 page_size = 2;
  string page_token = 3;
  bool include_inactive = 4;      // Include disabled connectors
}

message ListConnectorsResponse {
  repeated ConnectorRegistration connectors = 1;
  string next_page_token = 2;
  int32 total_count = 3;
}

message SetConnectorStatusRequest {
  string connector_id = 1;
  bool active = 2;
  string reason = 3;              // Why it's being disabled
}

message SetConnectorStatusResponse {
  bool success = 1;
  string message = 2;
}

message DeleteConnectorRequest {
  string connector_id = 1;
  bool hard_delete = 2;           // If true, permanently delete
}

message DeleteConnectorResponse {
  bool success = 1;
  string message = 2;
  int32 crawl_sessions_deleted = 3;
}

message RotateApiKeyRequest {
  string connector_id = 1;
  bool invalidate_old_immediately = 2;  // Or allow grace period
}

message RotateApiKeyResponse {
  bool success = 1;
  string new_api_key = 2;
  google.protobuf.Timestamp old_key_expires = 3;  // When old key stops working
  string message = 4;
}

message GetCrawlHistoryRequest {
  string connector_id = 1;
  int32 limit = 2;                // Number of sessions to return
  string page_token = 3;
}

message GetCrawlHistoryResponse {
  repeated CrawlSessionSummary sessions = 1;
  string next_page_token = 2;
}

message CrawlSessionSummary {
  string session_id = 1;
  string crawl_id = 2;
  google.protobuf.Timestamp started_at = 3;
  google.protobuf.Timestamp completed_at = 4;
  int32 documents_found = 5;
  int32 documents_processed = 6;
  int32 documents_failed = 7;
  int64 bytes_processed = 8;
  string status = 9;              // "RUNNING", "COMPLETED", "FAILED"
  map<string, string> metadata = 10;
}